{
    "model_args": {
        "model_name": "wings_qwen2",
        "model_path": "Qwen/Qwen1.5-7B-Chat",
        "vision_tower": "google/siglip-so400m-patch14-384",
        "mm_vision_select_layer": -2,
        "mm_projector_type": "mlp2x_gelu",
        "mm_patch_merge_type": "flat",
        "mm_vision_select_feature": "patch",
        "system_prompt_length": 14,
        "model_max_length": 2048,
        "model_safetensors_load_path": "your_trained_safetensors_file_path",
        "moe_tune_mm_projector": true,
        "v_enable": false,
        "dmoe_enable": false,
        "dmoe_tune_mm_projector": true,
        "dmoe_params_init_mode": "copy",
        "dmoe_mode": "",
        "damoe_enable": false,
        "dlmoe_enable": false,
        "dlatt_enable": false,
        "dlora_enable": false,
        "damoe_ep_size": 1,
        "damoe_top_k_experts": 2,
        "damoe_capacity_factor": 1.0,
        "damoe_eval_capacity_factor": 2.0,
        "damoe_min_capacity": 0,
        "damoe_use_residual": false,
        "damoe_router_aux_loss_coef": 0.01,
        "peft_enable": false,
        "peft_mode": "",
        "peft_kwargs_k": [],
        "peft_kwargs_v": [],
        "lora_enable": false,
        "lora_r": false,
        "lora_dim": 64,
        "attn_layers_idx": [
            0,
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
            12,
            13,
            14,
            15,
            16,
            17,
            18,
            19,
            20,
            21,
            22,
            23,
            24,
            25,
            26,
            27,
            28,
            29,
            30,
            31
        ],
        "wings_router_type": "linear",
        "moe_enable": false,
        "moe_mode": "second_half",
        "ep_size": 1,
        "top_k_experts": 2,
        "capacity_factor": 1.0,
        "eval_capacity_factor": 2.0,
        "min_capacity": 0,
        "use_residual": false,
        "router_aux_loss_coef": 0.01
    },
    "data_args": {
        "data_name": "",
        "is_multimodal": true,
        "image_aspect_ratio": "pad",
        "only_image_data": false,
        "image_text_data_ratio": 0.0,
        "image_token_length": 729,
        "data": "",
        "model": "",
        "work_dir": ".",
        "mode": "all",
        "nproc": 4,
        "ignore": false,
        "verbose": false,
        "prefetch": false,
        "time_str": ""
    },
    "training_args": {
        "output_dir": "temp",
        "overwrite_output_dir": false,
        "do_train": false,
        "do_eval": false,
        "do_predict": false,
        "evaluation_strategy": "no",
        "prediction_loss_only": false,
        "per_device_train_batch_size": 4,
        "per_device_eval_batch_size": 8,
        "gradient_accumulation_steps": 2,
        "eval_delay": 0,
        "learning_rate": 2e-06,
        "weight_decay": 1e-08,
        "adam_beta1": 0.9,
        "adam_beta2": 0.999,
        "adam_epsilon": 1e-08,
        "max_grad_norm": 1.0,
        "num_train_epochs": 1.0,
        "max_steps": -1,
        "lr_scheduler_type": "cosine",
        "warmup_ratio": 0.03,
        "warmup_steps": 0,
        "log_level": "passive",
        "log_level_replica": "warning",
        "log_on_each_node": true,
        "logging_dir": "",
        "logging_strategy": "steps",
        "logging_first_step": false,
        "logging_steps": 1.0,
        "logging_nan_inf_filter": true,
        "save_strategy": "steps",
        "save_steps": 2000,
        "save_total_limit": 1,
        "save_safetensors": true,
        "save_on_each_node": false,
        "save_only_model": false,
        "no_cuda": false,
        "use_cpu": false,
        "use_mps_device": false,
        "seed": 42,
        "jit_mode_eval": false,
        "use_ipex": false,
        "bf16": true,
        "fp16": false,
        "fp16_opt_level": "O1",
        "half_precision_backend": "auto",
        "bf16_full_eval": false,
        "fp16_full_eval": false,
        "tf32": true,
        "local_rank": 0,
        "tpu_metrics_debug": false,
        "debug": [],
        "dataloader_drop_last": false,
        "dataloader_num_workers": 4,
        "past_index": -1,
        "run_name": "",
        "disable_tqdm": false,
        "remove_unused_columns": false,
        "load_best_model_at_end": false,
        "ignore_data_skip": false,
        "fsdp": [],
        "fsdp_min_num_params": 0,
        "label_smoothing_factor": 0.0,
        "optim": "adamw_torch",
        "adafactor": false,
        "group_by_length": false,
        "length_column_name": "length",
        "report_to": [],
        "dataloader_pin_memory": true,
        "dataloader_persistent_workers": false,
        "skip_memory_metrics": true,
        "use_legacy_prediction_loop": false,
        "push_to_hub": false,
        "hub_strategy": "every_save",
        "hub_private_repo": false,
        "hub_always_push": false,
        "gradient_checkpointing": true,
        "include_inputs_for_metrics": false,
        "fp16_backend": "auto",
        "mp_parameters": "",
        "auto_find_batch_size": false,
        "full_determinism": false,
        "ray_scope": "last",
        "ddp_timeout": 1800,
        "torch_compile": false,
        "include_tokens_per_second": false,
        "include_num_input_tokens_seen": false,
        "mm_projector_lr": 1e-05,
        "vision_tower_lr_follow_mm_projector": true,
        "lr_projector_follow_tuned_keys": [
            "mm_projector"
        ],
        "group_by_modality_length": false,
        "use_cache": false,
        "tuned_keys": [
            ".attn_pool.",
            ".attn_t_pool.",
            ".reweight_module."
        ],
        "tune_mm_projector": true,
        "tune_llm": true,
        "tune_vision_tower": false,
        "tune_only_mm_mlp_adapter": false
    }
}